
@article{baayen_mixed-effects_2008,
	title = {Mixed-effects modeling with crossed random effects for subjects and items},
	volume = {59},
	issn = {0749-596X},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X07001398},
	doi = {10.1016/j.jml.2007.12.005},
	abstract = {This paper provides an introduction to mixed-effects models for the analysis of repeated measurement data with subjects and items as crossed random effects. A worked-out example of how to use recent software for mixed-effects modeling is provided. Simulation studies illustrate the advantages offered by mixed-effects analyses compared to traditional analyses based on quasi-F tests, by-subjects analyses, combined by-subjects and by-items analyses, and random regression. Applications and possibilities across a range of domains of inquiry are discussed.},
	number = {4},
	journal = {Special Issue: Emerging Data Analysis},
	author = {Baayen, R.H. and Davidson, D.J. and Bates, D.M.},
	month = nov,
	year = {2008},
	keywords = {By-item, By-subject, Crossed random effects, Mixed-effects models, Quasi-F, notion},
	pages = {390--412},
}

@incollection{singmann_introduction_2019,
	title = {An {Introduction} to {Mixed} {Models} for {Experimental} {Psychology}},
	isbn = {978-0-429-31840-5},
	booktitle = {New {Methods} in {Cognitive} {Psychology}},
	author = {Singmann, Henrik and Kellen, David},
	month = oct,
	year = {2019},
	doi = {10.4324/9780429318405-2},
	note = {Journal Abbreviation: New Methods in Cognitive Psychology},
	keywords = {notion},
	pages = {4--31},
}

@article{krzywinski_nested_2014,
	title = {Nested designs},
	volume = {11},
	issn = {1548-7091},
	doi = {10.1038/nmeth.3137},
	abstract = {For studies with hierarchical noise sources, use a nested analysis of variance approach.},
	number = {10},
	journal = {Nature Methods},
	author = {Krzywinski, Martin and Altman, Naomi and Blainey, Paul},
	year = {2014},
	keywords = {notion},
	pages = {977--978},
}

@article{andersen_bottom-up_2012,
	title = {Bottom-{Up} {Biases} in {Feature}-{Selective} {Attention}},
	volume = {32},
	doi = {10.1523/JNEUROSCI.1767-12.2012},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Andersen, Søren and Müller, Matthias and Martinovic, Jasna},
	month = nov,
	year = {2012},
	keywords = {notion},
	pages = {16953--8},
}

@article{stadler_statistical_2021,
	title = {Statistical modeling of dynamic eye-tracking experiments: {Relative} importance of visual stimulus elements for gaze behavior in the multi-group case},
	volume = {53},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-021-01576-8},
	doi = {10.3758/s13428-021-01576-8},
	abstract = {This paper presents a model that allows group comparisons of gaze behavior while watching dynamic video stimuli. The model is based on the approach of Coutrot and Guyader (2017) and allows linear combinations of feature maps to form a master saliency map. The feature maps in the model are, for example, the dynamically salient contents of a video stimulus or predetermined areas of interest. The model takes into account temporal aspects of the stimuli, which is a crucial difference to other common models. The multi-group extension of the model introduced here allows to obtain relative importance plots, which visualize the effect of a specific feature of a stimulus on the attention and visual behavior for two or more experimental groups. These plots are interpretable summaries of data with high spatial and temporal resolution. This approach differs from many common methods for comparing gaze behavior between natural groups, which usually only include single-dimensional features such as the duration of fixation on a particular part of the stimulus. The method is illustrated by contrasting a sample of a group of persons with particularly high cognitive abilities (high achievement on IQ tests) with a control group on a psycholinguistic task on the conceptualization of motion events. In the example, we find no substantive differences in relative importance, but more exploratory gaze behavior in the highly gifted group. The code, videos, and eye-tracking data we used for this study are available online.},
	number = {6},
	journal = {Behavior Research Methods},
	author = {Stadler, Mara and Doebler, Philipp and Mertins, Barbara and Delucchi Danhier, Renate},
	month = dec,
	year = {2021},
	keywords = {notion},
	pages = {2650--2667},
}

@article{schielzeth_conclusions_2009,
	title = {Conclusions beyond support: overconfident estimates in mixed models},
	volume = {20},
	issn = {1045-2249},
	url = {https://doi.org/10.1093/beheco/arn145},
	doi = {10.1093/beheco/arn145},
	abstract = {Mixed-effect models are frequently used to control for the nonindependence of data points, for example, when repeated measures from the same individuals are available. The aim of these models is often to estimate fixed effects and to test their significance. This is usually done by including random intercepts, that is, intercepts that are allowed to vary between individuals. The widespread belief is that this controls for all types of pseudoreplication within individuals. Here we show that this is not the case, if the aim is to estimate effects that vary within individuals and individuals differ in their response to these effects. In these cases, random intercept models give overconfident estimates leading to conclusions that are not supported by the data. By allowing individuals to differ in the slopes of their responses, it is possible to account for the nonindependence of data points that pseudoreplicate slope information. Such random slope models give appropriate standard errors and are easily implemented in standard statistical software. Because random slope models are not always used where they are essential, we suspect that many published findings have too narrow confidence intervals and a substantially inflated type I error rate. Besides reducing type I errors, random slope models have the potential to reduce residual variance by accounting for between-individual variation in slopes, which makes it easier to detect treatment effects that are applied between individuals, hence reducing type II errors as well.},
	number = {2},
	urldate = {2022-12-10},
	journal = {Behavioral Ecology},
	author = {Schielzeth, Holger and Forstmeier, Wolfgang},
	month = mar,
	year = {2009},
	keywords = {notion},
	pages = {416--420},
}

@article{schielzeth_simple_2010,
	title = {Simple means to improve the interpretability of regression coefficients},
	volume = {1},
	issn = {2041-210X},
	url = {https://doi.org/10.1111/j.2041-210X.2010.00012.x},
	doi = {10.1111/j.2041-210X.2010.00012.x},
	abstract = {Summary 1. Linear regression models are an important statistical tool in evolutionary and ecological studies. Unfortunately, these models often yield some uninterpretable estimates and hypothesis tests, especially when models contain interactions or polynomial terms. Furthermore, the standard errors for treatment groups, although often of interest for including in a publication, are not directly available in a standard linear model. 2. Centring and standardization of input variables are simple means to improve the interpretability of regression coefficients. Further, refitting the model with a slightly modified model structure allows extracting the appropriate standard errors for treatment groups directly from the model. 3. Centring will make main effects biologically interpretable even when involved in interactions and thus avoids the potential misinterpretation of main effects. This also applies to the estimation of linear effects in the presence of polynomials. Categorical input variables can also be centred and this sometimes assists interpretation. 4. Standardization (z-transformation) of input variables results in the estimation of standardized slopes or standardized partial regression coefficients. Standardized slopes are comparable in magnitude within models as well as between studies. They have some advantages over partial correlation coefficients and are often the more interesting standardized effect size. 5. The thoughtful removal of intercepts or main effects allows extracting treatment means or treatment slopes and their appropriate standard errors directly from a linear model. This provides a simple alternative to the more complicated calculation of standard errors from contrasts and main effects. 6. The simple methods presented here put the focus on parameter estimation (point estimates as well as confidence intervals) rather than on significance thresholds. They allow fitting complex, but meaningful models that can be concisely presented and interpreted. The presented methods can also be applied to generalised linear models (GLM) and linear mixed models.},
	number = {2},
	urldate = {2022-10-11},
	journal = {Methods in Ecology and Evolution},
	author = {Schielzeth, Holger},
	month = jun,
	year = {2010},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {confidence intervals, generalized linear models, interaction terms, null hypothesis testing, partial correlation coefficients, partial regression coefficients, standard errors, standardized effects sizes, notion},
	pages = {103--113},
	annote = {https://doi.org/10.1111/j.2041-210X.2010.00012.x},
}

@article{chun_contextual_1998,
	title = {Contextual {Cueing}: {Implicit} {Learning} and {Memory} of {Visual} {Context} {Guides} {Spatial} {Attention}},
	volume = {36},
	issn = {0010-0285},
	url = {https://www.sciencedirect.com/science/article/pii/S0010028598906818},
	doi = {10.1006/cogp.1998.0681},
	abstract = {Global context plays an important, but poorly understood, role in visual tasks. This study demonstrates that a robust memory for visual context exists to guide spatial attention. Global context was operationalized as the spatial layout of objects in visual search displays. Half of the configurations were repeated across blocks throughout the entire session, and targets appeared within consistent locations in these arrays. Targets appearing in learned configurations were detected more quickly. This newly discovered form of search facilitation is termed contextual cueing. Contextual cueing is driven by incidentally learned associations between spatial configurations (context) and target locations. This benefit was obtained despite chance performance for recognizing the configurations, suggesting that the memory for context was implicit. The results show how implicit learning and memory of visual context can guide spatial attention towards task-relevant aspects of a scene.},
	number = {1},
	journal = {Cognitive Psychology},
	author = {Chun, Marvin M. and Jiang, Yuhong},
	month = jun,
	year = {1998},
	keywords = {notion},
	pages = {28--71},
}

@article{pollmann_working_2019,
	title = {Working memory dependence of spatial contextual cueing for visual search},
	volume = {110},
	issn = {0007-1269},
	url = {https://doi.org/10.1111/bjop.12311},
	doi = {10.1111/bjop.12311},
	abstract = {When spatial stimulus configurations repeat in visual search, a search facilitation, resulting in shorter search times, can be observed that is due to incidental learning. This contextual cueing effect appears to be rather implicit, uncorrelated with observers? explicit memory of display configurations. Nevertheless, as I review here, this search facilitation due to contextual cueing depends on visuospatial working memory resources, and it disappears when visuospatial working memory is loaded by a concurrent delayed match to sample task. However, the search facilitation immediately recovers for displays learnt under visuospatial working memory load when this load is removed in a subsequent test phase. Thus, latent learning of visuospatial configurations does not depend on visuospatial working memory, but the expression of learning, as memory-guided search in repeated displays, does. This working memory dependence has also consequences for visual search with foveal vision loss, where top-down controlled visual exploration strategies pose high demands on visuospatial working memory, in this way interfering with memory-guided search in repeated displays. Converging evidence for the contribution of working memory to contextual cueing comes from neuroimaging data demonstrating that distinct cortical areas along the intraparietal sulcus as well as more ventral parieto-occipital cortex are jointly activated by visual working memory and contextual cueing.},
	number = {2},
	urldate = {2022-10-13},
	journal = {British Journal of Psychology},
	author = {Pollmann, Stefan},
	month = may,
	year = {2019},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {contextual cueing, visuospatial, working memory, notion},
	pages = {372--380},
	annote = {https://doi.org/10.1111/bjop.12311},
}

@article{chun_contextual_2000,
	title = {Contextual cueing of visual attention},
	volume = {4},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661300014765},
	doi = {10.1016/S1364-6613(00)01476-5},
	abstract = {Visual context information constrains what to expect and where to look, facilitating search for and recognition of objects embedded in complex displays. This article reviews a new paradigm called contextual cueing, which presents well-defined, novel visual contexts and aims to understand how contextual information is learned and how it guides the deployment of visual attention. In addition, the contextual cueing task is well suited to the study of the neural substrate of contextual learning. For example, amnesic patients with hippocampal damage are impaired in their learning of novel contextual information, even though learning in the contextual cueing task does not appear to rely on conscious retrieval of contextual memory traces. We argue that contextual information is important because it embodies invariant properties of the visual environment such as stable spatial layout information as well as object covariation information. Sensitivity to these statistical regularities allows us to interact more effectively with the visual world.},
	number = {5},
	journal = {Trends in Cognitive Sciences},
	author = {Chun, Marvin M.},
	month = may,
	year = {2000},
	keywords = {Perceptual learning, Attention, Context, Hippocampus, Implicit learning, Implicit memory, Search, notion},
	pages = {170--178},
}

@article{makovski_contextual_2010,
	title = {Contextual cost: {When} a visual-search target is not where it should be},
	volume = {63},
	issn = {1747-0218},
	url = {https://doi.org/10.1080/17470210903281590},
	doi = {10.1080/17470210903281590},
	abstract = {Visual search is often facilitated when the search display occasionally repeats, revealing a contextual-cueing effect. According to the associative-learning account, contextual cueing arises from associating the display configuration with the target location. However, recent findings emphasizing the importance of local context near the target have given rise to the possibility that low-level repetition priming may account for the contextual-cueing effect. This study distinguishes associative learning from local repetition priming by testing whether search is directed toward a target's expected location, even when the target is relocated. After participants searched for a T among Ls in displays that repeated 24 times, they completed a transfer session where the target was relocated locally to a previously blank location (Experiment 1) or to an adjacent distractor location (Experiment 2). Results revealed that contextual cueing decreased as the target appeared farther away from its expected location, ultimately resulting in a contextual cost when the target swapped locations with a local distractor. We conclude that target predictability is a key factor in contextual cueing.},
	number = {2},
	urldate = {2022-10-13},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {Makovski, Tal and Jiang, Yuhong V.},
	month = feb,
	year = {2010},
	note = {Publisher: SAGE Publications},
	keywords = {notion},
	pages = {216--225},
	annote = {doi: 10.1080/17470210903281590},
}

@article{mack_object_2011,
	title = {Object co-occurrence serves as a contextual cue to guide and facilitate visual search in a natural viewing environment},
	volume = {11},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/11.9.9},
	doi = {10.1167/11.9.9},
	abstract = {There is accumulating evidence that scene context can guide and facilitate visual search (e.g., A. Torralba, A. Oliva, M. S. Castelhano, \&amp; J. M. Henderson, 2006). Previous studies utilized stimuli of restricted size, a fixed head position, and context defined by the global spatial configuration of the scene. Thus, it is unknown whether similar effects generalize to natural viewing environments and to context defined by local object co-occurrence. Here, with a mobile eye tracker, we investigated the effects of object co-occurrence on search performance under naturalistic conditions. Observers searched for low-visibility target objects on tables cluttered with everyday objects. Targets were either located adjacent to larger, more visible “cue” objects that they regularly co-occurred in natural scenes (expected condition) or elsewhere in the display, surrounded by unrelated objects (unexpected condition). Mean search times were shorter for targets at expected locations as compared to unexpected locations. Additionally, context guided eye movements, as more fixations were directed toward cue objects than other non-target objects, particularly when the cue was contextually relevant to the current search target. These results could not be accounted for by image saliency models. Thus, we conclude that object co-occurrence can serve as a contextual cue to facilitate search and guide eye movements in natural environments.},
	number = {9},
	urldate = {2022-10-13},
	journal = {Journal of Vision},
	author = {Mack, Stephen C. and Eckstein, Miguel P.},
	month = aug,
	year = {2011},
	keywords = {notion},
	pages = {9--9},
}

@article{schlagbauer_awareness_2012,
	title = {Awareness in contextual cueing of visual search as measured with concurrent access- and phenomenal-consciousness tasks},
	volume = {12},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/12.11.25},
	doi = {10.1167/12.11.25},
	abstract = {In visual search, context information can serve as a cue to guide attention to the target location. When observers repeatedly encounter displays with identical target-distractor arrangements, reaction times (RTs) are faster for repeated relative to nonrepeated displays, the latter containing novel configurations. This effect has been termed “contextual cueing.” The present study asked whether information about the target location in repeated displays is “explicit” (or “conscious”) in nature. To examine this issue, observers performed a test session (after an initial training phase in which RTs to repeated and nonrepeated displays were measured) in which the search stimuli were presented briefly and terminated by visual masks; following this, observers had to make a target localization response (with accuracy as the dependent measure) and indicate their visual experience and confidence associated with the localization response. The data were examined at the level of individual displays, i.e., in terms of whether or not a repeated display actually produced contextual cueing. The results were that (a) contextual cueing was driven by only a very small number of about four actually learned configurations; (b) localization accuracy was increased for learned relative to nonrepeated displays; and (c) both consciousness measures were enhanced for learned compared to nonrepeated displays. It is concluded that contextual cueing is driven by only a few repeated displays and the ability to locate the target in these displays is associated with increased visual experience.},
	number = {11},
	urldate = {2022-10-13},
	journal = {Journal of Vision},
	author = {Schlagbauer, Bernhard and Müller, Hermann J. and Zehetleitner, Michael and Geyer, Thomas},
	month = oct,
	year = {2012},
	keywords = {notion},
	pages = {25--25},
}

@article{conci_limitations_2011,
	title = {Limitations of perceptual segmentation on contextual cueing in visual search},
	volume = {19},
	issn = {1350-6285},
	url = {https://doi.org/10.1080/13506285.2010.518574},
	doi = {10.1080/13506285.2010.518574},
	number = {2},
	journal = {Visual Cognition},
	author = {Conci, Markus and von Mühlenen, Adrian},
	month = feb,
	year = {2011},
	note = {Publisher: Routledge},
	keywords = {notion},
	pages = {203--233},
	annote = {doi: 10.1080/13506285.2010.518574},
}

@article{brockmole_recognition_2006,
	title = {Recognition and attention guidance during contextual cueing in real-world scenes: {Evidence} from eye movements},
	volume = {59},
	issn = {1747-0218},
	url = {https://doi.org/10.1080/17470210600665996},
	doi = {10.1080/17470210600665996},
	number = {7},
	journal = {The Quarterly Journal of Experimental Psychology},
	author = {Brockmole, James   R. and Henderson, John   M.},
	month = jul,
	year = {2006},
	note = {Publisher: Routledge},
	keywords = {notion},
	pages = {1177--1187},
	annote = {doi: 10.1080/17470210600665996},
}

@article{manginelli_misleading_2009,
	title = {Misleading contextual cues: {How} do they affect visual search?},
	volume = {73},
	issn = {1430-2772},
	url = {https://doi.org/10.1007/s00426-008-0211-1},
	doi = {10.1007/s00426-008-0211-1},
	abstract = {Contextual cueing occurs when repetitions of the distractor configuration are implicitly learned. This implicit learning leads to faster search times in repeated displays. Here, we investigated how search adapts to a change of the target location in old displays from a consistent location in the learning phase to a consistent new location in the transfer phase. In agreement with the literature, contextual cueing was accompanied by fewer fixations, a more efficient scan path and, specifically, an earlier onset of a monotonic gaze approach phase towards the target location in repeated displays. When the repeated context was no longer predictive of the old target location, search times and number of fixations for old displays increased to the level of novel displays. Along with this, scan paths for old and new displays became equally efficient. After the target location change, there was a bias of exploration towards the old target location, which soon disappeared. Thus, change of implicitly learned spatial relations between target and distractor configuration eliminated the advantageous effects of contextual cueing, but did not lead to a lasting impairment of search in repeated displays relative to novel displays.},
	number = {2},
	journal = {Psychological Research},
	author = {Manginelli, Angela A. and Pollmann, Stefan},
	month = mar,
	year = {2009},
	keywords = {notion},
	pages = {212--221},
}

@article{zellin_here_2013,
	title = {Here {Today}, {Gone} {Tomorrow} – {Adaptation} to {Change} in {Memory}-{Guided} {Visual} {Search}},
	volume = {8},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0059466},
	doi = {10.1371/journal.pone.0059466},
	abstract = {Visual search for a target object can be facilitated by the repeated presentation of an invariant configuration of nontargets (‘contextual cueing’). Here, we tested adaptation of learned contextual associations after a sudden, but permanent, relocation of the target. After an initial learning phase targets were relocated within their invariant contexts and repeatedly presented at new locations, before they returned to the initial locations. Contextual cueing for relocated targets was neither observed after numerous presentations nor after insertion of an overnight break. Further experiments investigated whether learning of additional, previously unseen context-target configurations is comparable to adaptation of existing contextual associations to change. In contrast to the lack of adaptation to changed target locations, contextual cueing developed for additional invariant configurations under identical training conditions. Moreover, across all experiments, presenting relocated targets or additional contexts did not interfere with contextual cueing of initially learned invariant configurations. Overall, the adaptation of contextual memory to changed target locations was severely constrained and unsuccessful in comparison to learning of an additional set of contexts, which suggests that contextual cueing facilitates search for only one repeated target location.},
	number = {3},
	urldate = {2022-10-13},
	journal = {PLOS ONE},
	author = {Zellin, Martina and Conci, Markus and Mühlenen, Adrian von and Müller, Hermann J.},
	month = mar,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Learning, Adults, Analysis of variance, Experimental design, Sensory cues, Target detection, Vision, Visual acuity, notion},
	pages = {e59466},
	file = {Full Text PDF:/Users/luca/Zotero/storage/9YXGMQ6T/Zellin et al. - 2013 - Here Today, Gone Tomorrow – Adaptation to Change i.pdf:application/pdf;Snapshot:/Users/luca/Zotero/storage/JCTRQ87E/citation.html:text/html},
}

@article{makovski_meaning_2018,
	title = {Meaning in learning: {Contextual} cueing relies on objects’ visual features and not on objects’ meaning},
	volume = {46},
	issn = {1532-5946},
	url = {https://doi.org/10.3758/s13421-017-0745-9},
	doi = {10.3758/s13421-017-0745-9},
	abstract = {People easily learn regularities embedded in the environment and utilize them to facilitate visual search. Using images of real-world objects, it has been recently shown that this learning, termed contextual cueing (CC), occurs even in complex, heterogeneous environments, but only when the same distractors are repeated at the same locations. Yet it is not clear what exactly is being learned under these conditions: the visual features of the objects or their meaning. In this study, Experiment 1 demonstrated that meaning is not necessary for this type of learning, as a similar pattern of results was found even when the objects’ meaning was largely removed. Experiments 2 and 3 showed that after learning meaningful objects, CC was not diminished by a manipulation that distorted the objects’ meaning but preserved most of their visual properties. By contrast, CC was eliminated when the learned objects were replaced with different category exemplars that preserved the objects’ meaning but altered their visual properties. Together, these data strongly suggest that the acquired context that facilitates real-world objects search relies primarily on the visual properties and the spatial locations of the objects, but not on their meaning.},
	number = {1},
	journal = {Memory \& Cognition},
	author = {Makovski, Tal},
	month = jan,
	year = {2018},
	keywords = {notion},
	pages = {58--67},
}

@article{barr_random_2013,
	title = {Random effects structure for testing interactions in linear mixed-effects models},
	volume = {4},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00328},
	journal = {Frontiers in Psychology},
	author = {Barr, Dale},
	year = {2013},
	keywords = {notion},
}

@article{heisig_why_2019,
	title = {Why {You} {Should} {Always} {Include} a {Random} {Slope} for the {Lower}-{Level} {Variable} {Involved} in a {Cross}-{Level} {Interaction}},
	volume = {35},
	issn = {0266-7215},
	url = {https://doi.org/10.1093/esr/jcy053},
	doi = {10.1093/esr/jcy053},
	abstract = {Mixed-effects multilevel models are often used to investigate cross-level interactions, a specific type of context effect that may be understood as an upper-level variable moderating the association between a lower-level predictor and the outcome. We argue that multilevel models involving cross-level interactions should always include random slopes on the lower-level components of those interactions. Failure to do so will usually result in severely anti-conservative statistical inference. We illustrate the problem with extensive Monte Carlo simulations and examine its practical relevance by studying 30 prototypical cross-level interactions with European Social Survey data for 28 countries. In these empirical applications, introducing a random slope term reduces the absolute t-ratio of the cross-level interaction term by 31 per cent or more in three quarters of cases, with an average reduction of 42 per cent. Many practitioners seem to be unaware of these issues. Roughly half of the cross-level interaction estimates published in the European Sociological Review between 2011 and 2016 are based on models that omit the crucial random slope term. Detailed analysis of the associated test statistics suggests that many of the estimates would not reach conventional thresholds for statistical significance in correctly specified models that include the random slope. This raises the question how much robust evidence of cross-level interactions sociology has actually produced over the past decades.},
	number = {2},
	urldate = {2022-10-13},
	journal = {European Sociological Review},
	author = {Heisig, Jan Paul and Schaeffer, Merlin},
	month = apr,
	year = {2019},
	keywords = {notion},
	pages = {258--279},
}

@book{hox_multilevel_2017,
	address = {New York},
	edition = {3},
	title = {Multilevel {Analysis}: {Techniques} and {Applications}},
	isbn = {978-1-315-65098-2},
	shorttitle = {Multilevel {Analysis}},
	abstract = {Applauded for its clarity, this accessible introduction helps readers apply multilevel techniques to their research. The book also includes advanced extensions, making it useful as both an introduction for students and as a reference for researchers. Basic models and examples are discussed in nontechnical terms with an emphasis on understanding the methodological and statistical issues involved in using these models. The estimation and interpretation of multilevel models is demonstrated using realistic examples from various disciplines including psychology, education, public health, and sociology. Readers are introduced to a general framework on multilevel modeling which covers both observed and latent variables in the same model, while most other books focus on observed variables. In addition, Bayesian estimation is introduced and applied using accessible software.},
	publisher = {Routledge},
	author = {Hox, Joop and Moerbeek, Mirjam and Schoot, Rens van de},
	month = sep,
	year = {2017},
	doi = {10.4324/9781315650982},
	keywords = {notion},
}

@article{gurka_extending_2006,
	title = {Extending the {Box}–{Cox} transformation to the linear mixed model},
	volume = {169},
	issn = {0964-1998},
	url = {https://doi.org/10.1111/j.1467-985X.2005.00391.x},
	doi = {10.1111/j.1467-985X.2005.00391.x},
	abstract = {Summary.? For a univariate linear model, the Box?Cox method helps to choose a response transformation to ensure the validity of a Gaussian distribution and related assumptions. The desire to extend the method to a linear mixed model raises many vexing questions. Most importantly, how do the distributions of the two sources of randomness (pure error and random effects) interact in determining the validity of assumptions? For an otherwise valid model, we prove that the success of a transformation may be judged solely in terms of how closely the total error follows a Gaussian distribution. Hence the approach avoids the complexity of separately evaluating pure errors and random effects. The extension of the transformation to the mixed model requires an exploration of its potential effect on estimation and inference of the model parameters. Analysis of longitudinal pulmonary function data and Monte Carlo simulations illustrate the methodology discussed.},
	number = {2},
	urldate = {2022-10-15},
	journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
	author = {Gurka, Matthew J. and Edwards, Lloyd J. and Muller, Keith E. and Kupper, Lawrence L.},
	month = mar,
	year = {2006},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Linear mixed model, Longitudinal data, Lung function, Normality, Random effects, Transformation, notion},
	pages = {273--288},
	annote = {https://doi.org/10.1111/j.1467-985X.2005.00391.x},
}

@article{thai_comparison_2013,
	title = {A comparison of bootstrap approaches for estimating uncertainty of parameters in linear mixed-effects models},
	volume = {12},
	doi = {10.1002/pst.1561},
	journal = {Pharmaceutical statistics},
	author = {Thai, Hoai-Thu and Mentré, France and Holford, Nick and Veyrat-Follet, Christine and Comets, Emmanuelle},
	month = may,
	year = {2013},
	keywords = {notion},
}

@article{peirce_psychopy2_2019,
	title = {{PsychoPy2}: {Experiments} in behavior made easy},
	volume = {51},
	issn = {1554-3528},
	shorttitle = {{PsychoPy2}},
	url = {https://doi.org/10.3758/s13428-018-01193-y},
	doi = {10.3758/s13428-018-01193-y},
	abstract = {PsychoPy is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch PsychoPy every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
	language = {en},
	number = {1},
	urldate = {2022-10-17},
	journal = {Behavior Research Methods},
	author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and MacAskill, Michael and Höchenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindeløv, Jonas Kristoffer},
	month = feb,
	year = {2019},
	keywords = {Psychology, Experiment, Open science, Open-source, Reaction time, Software, Timing, notion},
	pages = {195--203},
	file = {Full Text PDF:/Users/luca/Zotero/storage/JHP9DQRN/Peirce et al. - 2019 - PsychoPy2 Experiments in behavior made easy.pdf:application/pdf},
}

@article{peirce_psychopy2_2019-1,
	title = {{PsychoPy2}: {Experiments} in behavior made easy},
	volume = {51},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-018-01193-y},
	doi = {10.3758/s13428-018-01193-y},
	abstract = {PsychoPy is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch PsychoPy every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
	number = {1},
	journal = {Behavior Research Methods},
	author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and MacAskill, Michael and Höchenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindeløv, Jonas Kristoffer},
	month = feb,
	year = {2019},
	keywords = {notion},
	pages = {195--203},
}

@misc{r_core_team_r_2022,
	address = {Vienna, Austria},
	title = {R: {A} language and   environment for statistical computing},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {R Core Team},
	year = {2022},
}

@misc{rstudio_team_rstudio_2022,
	address = {Boston, MA},
	title = {{RStudio}: {Integrated} {Development} {Environment}   for {R}},
	url = {http://www.rstudio.com/.},
	publisher = {RStudio, PBC},
	author = {RStudio Team},
	year = {2022},
}

@article{wickham_welcome_2019,
	title = {Welcome to the {Tidyverse}},
	volume = {4},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.01686},
	doi = {10.21105/joss.01686},
	abstract = {Wickham et al., (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686},
	language = {en},
	number = {43},
	urldate = {2022-10-17},
	journal = {Journal of Open Source Software},
	author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and François, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and Müller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
	month = nov,
	year = {2019},
	pages = {1686},
	file = {Full Text PDF:/Users/luca/Zotero/storage/ZAHPL6ML/Wickham et al. - 2019 - Welcome to the Tidyverse.pdf:application/pdf;Snapshot:/Users/luca/Zotero/storage/4PA3VSPY/joss.html:text/html},
}

@misc{wickham_dplyr_2022,
	title = {dplyr: {A} {Grammar} of {Data} {Manipulation}},
	copyright = {MIT + file LICENSE},
	shorttitle = {dplyr},
	url = {https://CRAN.R-project.org/package=dplyr},
	abstract = {A fast, consistent tool for working with data frame like objects, both in memory and out of memory.},
	urldate = {2022-10-17},
	author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill and RStudio},
	month = sep,
	year = {2022},
	keywords = {Databases, ModelDeployment, Epidemiology},
}

@misc{wickham_readr_2022,
	title = {readr: {Read} {Rectangular} {Text} {Data}},
	copyright = {MIT + file LICENSE},
	shorttitle = {readr},
	url = {https://CRAN.R-project.org/package=readr},
	abstract = {The goal of 'readr' is to provide a fast and friendly way to read rectangular data (like 'csv', 'tsv', and 'fwf'). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes.},
	urldate = {2022-10-17},
	author = {Wickham, Hadley and Hester, Jim and Francois, Romain and Bryan, Jennifer and Bearrows, Shelby and RStudio and library), https://github com/mandreyel/ (mio and implementation), Jukka Jylänki (grisu3 and implementation), Mikkel Jørgensen (grisu3},
	month = oct,
	year = {2022},
}

@misc{henry_purrr_2022,
	title = {purrr: {Functional} {Programming} {Tools}},
	copyright = {GPL-3 {\textbar} file LICENSE},
	shorttitle = {purrr},
	url = {https://CRAN.R-project.org/package=purrr},
	abstract = {A complete and consistent functional programming toolkit for R.},
	urldate = {2022-10-17},
	author = {Henry, Lionel and Wickham, Hadley and RStudio},
	month = oct,
	year = {2022},
}

@misc{wickham_tidyr_2022,
	title = {tidyr: {Tidy} {Messy} {Data}},
	copyright = {MIT + file LICENSE},
	shorttitle = {tidyr},
	url = {https://CRAN.R-project.org/package=tidyr},
	abstract = {Tools to help to create tidy data, where each column is a variable, each row is an observation, and each cell contains a single value. 'tidyr' contains tools for changing the shape (pivoting) and hierarchy (nesting and 'unnesting') of a dataset, turning deeply nested lists into rectangular data frames ('rectangling'), and extracting values out of string columns. It also includes tools for working with missing values (both implicit and explicit).},
	urldate = {2022-10-17},
	author = {Wickham, Hadley and Girlich, Maximilian and RStudio},
	month = sep,
	year = {2022},
	keywords = {MissingData},
}

@misc{wickham_stringr_2022,
	title = {stringr: {Simple}, {Consistent} {Wrappers} for {Common} {String} {Operations}},
	copyright = {GPL-2 {\textbar} file LICENSE},
	shorttitle = {stringr},
	url = {https://CRAN.R-project.org/package=stringr},
	abstract = {A consistent, simple and easy to use set of wrappers around the fantastic 'stringi' package. All function and argument names (and positions) are consistent, all functions deal with "NA"'s and zero length vectors in the same way, and the output from one function is easy to feed into the input of another.},
	urldate = {2022-10-17},
	author = {Wickham, Hadley and RStudio},
	month = aug,
	year = {2022},
}

@misc{wickham_forcats_2022,
	title = {forcats: {Tools} for {Working} with {Categorical} {Variables} ({Factors})},
	copyright = {MIT + file LICENSE},
	shorttitle = {forcats},
	url = {https://CRAN.R-project.org/package=forcats},
	abstract = {Helpers for reordering factor levels (including moving specified levels to front, ordering by first appearance, reversing, and randomly shuffling), and tools for modifying factor levels (including collapsing rare levels into other, 'anonymising', and manually 'recoding').},
	urldate = {2022-10-17},
	author = {Wickham, Hadley and RStudio},
	month = aug,
	year = {2022},
}

@misc{spinu_lubridate_2021,
	title = {lubridate: {Make} {Dealing} with {Dates} a {Little} {Easier}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {lubridate},
	url = {https://CRAN.R-project.org/package=lubridate},
	abstract = {Functions to work with date-times and time-spans: fast and user friendly parsing of date-time data, extraction and updating of components of a date-time (years, months, days, hours, minutes, and seconds), algebraic manipulation on date-time and time-span objects. The 'lubridate' package has a consistent and memorable syntax that makes working with dates easy and fun. Parts of the 'CCTZ' source code, released under the Apache 2.0 License, are included in this package. See {\textless}https://github.com/google/cctz{\textgreater} for more details.},
	urldate = {2022-10-17},
	author = {Spinu, Vitalie and Grolemund, Garrett and Wickham, Hadley and Vaughan, Davis and Lyttle, Ian and Costigan, Imanuel and Law, Jason and Mitarotonda, Doug and Larmarange, Joseph and Boiser, Jonathan and Lee, Chel Hee and Inc, Google},
	month = oct,
	year = {2021},
	keywords = {TimeSeries, ReproducibleResearch},
}

@misc{kuhn__aut_tidymodels_2022,
	title = {tidymodels: {Easily} {Install} and {Load} the '{Tidymodels}' {Packages}},
	copyright = {MIT + file LICENSE},
	shorttitle = {tidymodels},
	url = {https://CRAN.R-project.org/package=tidymodels},
	abstract = {The tidy modeling "verse" is a collection of packages for modeling and statistical analysis that share the underlying design philosophy, grammar, and data structures of the tidyverse.},
	urldate = {2022-10-17},
	author = {Kuhn  [aut, Max and cre and Wickham, Hadley and RStudio},
	month = jul,
	year = {2022},
	keywords = {MachineLearning},
}

@misc{kuhn_multilevelmod_2022,
	title = {multilevelmod: {Model} {Wrappers} for {Multi}-{Level} {Models}},
	copyright = {MIT + file LICENSE},
	shorttitle = {multilevelmod},
	url = {https://CRAN.R-project.org/package=multilevelmod},
	abstract = {Bindings for hierarchical regression models for use with the 'parsnip' package. Models include longitudinal generalized linear models (Liang and Zeger, 1986) {\textless}doi:10.1093/biomet/73.1.13{\textgreater}, and mixed-effect models (Pinheiro and Bates) {\textless}doi:10.1007/978-1-4419-0318-1\_1{\textgreater}.},
	urldate = {2022-10-17},
	author = {Kuhn, Max and Frick, Hannah and RStudio},
	month = jun,
	year = {2022},
}

@misc{bates_lme4_2022,
	title = {lme4: {Linear} {Mixed}-{Effects} {Models} using '{Eigen}' and {S4}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {lme4},
	url = {https://CRAN.R-project.org/package=lme4},
	abstract = {Fit linear and generalized linear mixed-effects models. The models and their components are represented using S4 classes and methods. The core computational algorithms are implemented using the 'Eigen' C++ library for numerical linear algebra and 'RcppEigen' "glue".},
	urldate = {2022-10-17},
	author = {Bates, Douglas and Maechler, Martin and Bolker  [aut, Ben and cre and Walker, Steven and Christensen, Rune Haubo Bojesen and Singmann, Henrik and Dai, Bin and Scheipl, Fabian and Grothendieck, Gabor and Green, Peter and Fox, John and Bauer, Alexander and simulate.formula), Pavel N. Krivitsky (shared copyright on},
	month = jul,
	year = {2022},
	keywords = {Psychometrics, Econometrics, Environmetrics, SpatioTemporal},
}

@misc{bolker__aut_broommixed_2022,
	title = {broom.mixed: {Tidying} {Methods} for {Mixed} {Models}},
	copyright = {GPL-3},
	shorttitle = {broom.mixed},
	url = {https://CRAN.R-project.org/package=broom.mixed},
	abstract = {Convert fitted objects from various R mixed-model packages into tidy data frames along the lines of the 'broom' package. The package provides three S3 generics for each model: tidy(), which summarizes a model's statistical findings such as coefficients of a regression; augment(), which adds columns to the original data such as predictions, residuals and cluster assignments; and glance(), which provides a one-row summary of model-level statistics.},
	urldate = {2022-10-17},
	author = {Bolker  [aut, Ben and cre and Robinson, David and Menne, Dieter and Gabry, Jonah and Buerkner, Paul and Hua, Christopher and Petry, William and Wiley, Joshua and Kennedy, Patrick and SE), Eduard Szöcs (BASF and Patil, Indrajeet and Arel-Bundock, Vincent and Denney, Bill and Brunson, Cory},
	month = apr,
	year = {2022},
}

@misc{peterson_bestnormalize_2022,
	title = {{bestNormalize}: {Normalizing} {Transformation} {Functions}},
	copyright = {GPL-3},
	shorttitle = {{bestNormalize}},
	url = {https://CRAN.R-project.org/package=bestNormalize},
	abstract = {Estimate a suite of normalizing transformations, including a new adaptation of a technique based on ranks which can guarantee normally distributed transformed data if there are no ties: ordered quantile normalization (ORQ). ORQ normalization combines a rank-mapping approach with a shifted logit approximation that allows the transformation to work on data outside the original domain. It is also able to handle new data within the original domain via linear interpolation. The package is built to estimate the best normalizing transformation for a vector consistently and accurately. It implements the Box-Cox transformation, the Yeo-Johnson transformation, three types of Lambert WxF transformations, and the ordered quantile normalization transformation. It estimates the normalization efficacy of other commonly used transformations, and it allows users to specify custom transformations or normalization statistics. Finally, functionality can be integrated into a machine learning workflow via recipes.},
	urldate = {2022-10-17},
	author = {Peterson, Ryan Andrew},
	month = jun,
	year = {2022},
}

@misc{wilke_ggridges_2022,
	title = {ggridges: {Ridgeline} {Plots} in 'ggplot2'},
	copyright = {GPL-2 {\textbar} file LICENSE},
	shorttitle = {ggridges},
	url = {https://CRAN.R-project.org/package=ggridges},
	abstract = {Ridgeline plots provide a convenient way of visualizing changes in distributions over time or space. This package enables the creation of such plots in 'ggplot2'.},
	urldate = {2022-10-17},
	author = {Wilke, Claus O.},
	month = sep,
	year = {2022},
}

@misc{wickham_ggplot2_2022,
	title = {ggplot2: {Create} {Elegant} {Data} {Visualisations} {Using} the {Grammar} of {Graphics}},
	copyright = {MIT + file LICENSE},
	shorttitle = {ggplot2},
	url = {https://CRAN.R-project.org/package=ggplot2},
	abstract = {A system for 'declaratively' creating graphics, based on "The Grammar of Graphics". You provide the data, tell 'ggplot2' how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.},
	urldate = {2022-10-17},
	author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey and RStudio},
	month = may,
	year = {2022},
	keywords = {TeachingStatistics, Spatial},
}

@misc{hester_glue_2022,
	title = {glue: {Interpreted} {String} {Literals}},
	copyright = {MIT + file LICENSE},
	shorttitle = {glue},
	url = {https://CRAN.R-project.org/package=glue},
	abstract = {An implementation of interpreted string literals, inspired by Python's Literal String Interpolation {\textless}https://www.python.org/dev/peps/pep-0498/{\textgreater} and Docstrings {\textless}https://www.python.org/dev/peps/pep-0257/{\textgreater} and Julia's Triple-Quoted String Literals {\textless}https://docs.julialang.org/en/v1.3/manual/strings/\#Triple-Quoted-String-Literals-1{\textgreater}.},
	urldate = {2022-10-17},
	author = {Hester, Jim and Bryan, Jennifer and RStudio},
	month = feb,
	year = {2022},
}

@misc{wilke_cowplot_2020,
	title = {cowplot: {Streamlined} {Plot} {Theme} and {Plot} {Annotations} for 'ggplot2'},
	copyright = {GPL-2},
	shorttitle = {cowplot},
	url = {https://CRAN.R-project.org/package=cowplot},
	abstract = {Provides various features that help with creating publication-quality figures with 'ggplot2', such as a set of themes, functions to align plots and arrange them into complex compound figures, and functions that make it easy to annotate plots and or mix plots with images. The package was originally written for internal use in the Wilke lab, hence the name (Claus O. Wilke's plot package). It has also been used extensively in the book Fundamentals of Data Visualization.},
	urldate = {2022-10-17},
	author = {Wilke, Claus O.},
	month = dec,
	year = {2020},
}

@misc{kay_ggdist_2022,
	title = {ggdist: {Visualizations} of {Distributions} and {Uncertainty}},
	copyright = {GPL (≥ 3)},
	shorttitle = {ggdist},
	url = {https://CRAN.R-project.org/package=ggdist},
	abstract = {Provides primitives for visualizing distributions using 'ggplot2' that are particularly tuned for visualizing uncertainty in either a frequentist or Bayesian mode. Both analytical distributions (such as frequentist confidence distributions or Bayesian priors) and distributions represented as samples (such as bootstrap distributions or Bayesian posterior samples) are easily visualized. Visualization primitives include but are not limited to: points with multiple uncertainty intervals, eye plots (Spiegelhalter D., 1999) {\textless}https://ideas.repec.org/a/bla/jorssa/v162y1999i1p45-58.html{\textgreater}, density plots, gradient plots, dot plots (Wilkinson L., 1999) {\textless}doi:10.1080/00031305.1999.10474474{\textgreater}, quantile dot plots (Kay M., Kola T., Hullman J., Munson S., 2016) {\textless}doi:10.1145/2858036.2858558{\textgreater}, complementary cumulative distribution function barplots (Fernandes M., Walls L., Munson S., Hullman J., Kay M., 2018) {\textless}doi:10.1145/3173574.3173718{\textgreater}, and fit curves with multiple uncertainty ribbons.},
	urldate = {2022-10-17},
	author = {Kay, Matthew and Wiernik, Brenton M.},
	month = jul,
	year = {2022},
}

@misc{tiedemann_gghalves_2022,
	title = {gghalves: {Compose} {Half}-{Half} {Plots} {Using} {Your} {Favourite} {Geoms}},
	copyright = {MIT + file LICENSE},
	shorttitle = {gghalves},
	url = {https://CRAN.R-project.org/package=gghalves},
	abstract = {A 'ggplot2' extension for easy plotting of half-half geom combinations. Think half boxplot and half jitterplot, or half violinplot and half dotplot.},
	urldate = {2022-10-17},
	author = {Tiedemann, Frederik},
	month = may,
	year = {2022},
}

@misc{details_sysfonts_2022,
	title = {sysfonts: {Loading} {Fonts} into {R}},
	copyright = {GPL-2},
	shorttitle = {sysfonts},
	url = {https://CRAN.R-project.org/package=sysfonts},
	abstract = {Loading system fonts and Google Fonts {\textless}https://fonts.google.com/{\textgreater} into R, in order to support other packages such as 'R2SWF' and 'showtext'.},
	urldate = {2022-10-17},
	author = {details, Yixuan Qiu {and} authors/contributors of the included fonts See file AUTHORS for details sysfonts author},
	month = mar,
	year = {2022},
}

@misc{details_showtext_2022,
	title = {showtext: {Using} {Fonts} {More} {Easily} in {R} {Graphs}},
	copyright = {Apache License (≥ 2.0)},
	shorttitle = {showtext},
	url = {https://CRAN.R-project.org/package=showtext},
	abstract = {Making it easy to use various types of fonts ('TrueType', 'OpenType', Type 1, web fonts, etc.) in R graphs, and supporting most output formats of R graphics including PNG, PDF and SVG. Text glyphs will be converted into polygons or raster images, hence after the plot has been created, it no longer relies on the font files. No external software such as 'Ghostscript' is needed to use this package.},
	urldate = {2022-10-17},
	author = {details, Yixuan Qiu {and} authors/contributors of the included software See file AUTHORS for details showtext author},
	month = feb,
	year = {2022},
}

@misc{campitelli_ggnewscale_2022,
	title = {ggnewscale: {Multiple} {Fill} and {Colour} {Scales} in 'ggplot2'},
	copyright = {GPL-3},
	shorttitle = {ggnewscale},
	url = {https://CRAN.R-project.org/package=ggnewscale},
	abstract = {Use multiple fill and colour scales in 'ggplot2'.},
	urldate = {2022-10-17},
	author = {Campitelli, Elio},
	month = oct,
	year = {2022},
}

@misc{ihaka_colorspace_2022,
	title = {colorspace: {A} {Toolbox} for {Manipulating} and {Assessing} {Colors} and {Palettes}},
	copyright = {BSD\_3\_clause + file LICENSE},
	shorttitle = {colorspace},
	url = {https://CRAN.R-project.org/package=colorspace},
	abstract = {Carries out mapping between assorted color spaces including RGB, HSV, HLS, CIEXYZ, CIELUV, HCL (polar CIELUV), CIELAB, and polar CIELAB. Qualitative, sequential, and diverging color palettes based on HCL colors are provided along with corresponding ggplot2 color scales. Color palette choice is aided by an interactive app (with either a Tcl/Tk or a shiny graphical user interface) and shiny apps with an HCL color picker and a color vision deficiency emulator. Plotting functions for displaying and assessing palettes include color swatches, visualizations of the HCL space, and trajectories in HCL and/or RGB spectrum. Color manipulation functions include: desaturation, lightening/darkening, mixing, and simulation of color vision deficiencies (deutanomaly, protanomaly, tritanomaly). Details can be found on the project web page at {\textless}https://colorspace.R-Forge.R-project.org/{\textgreater} and in the accompanying scientific paper: Zeileis et al. (2020, Journal of Statistical Software, {\textless}doi:10.18637/jss.v096.i01{\textgreater}).},
	urldate = {2022-10-17},
	author = {Ihaka, Ross and Murrell, Paul and Hornik, Kurt and Fisher, Jason C. and Stauffer, Reto and Wilke, Claus O. and McWhite, Claire D. and Zeileis, Achim},
	month = feb,
	year = {2022},
}

@misc{wilke_ggtext_2022,
	title = {ggtext: {Improved} {Text} {Rendering} {Support} for 'ggplot2'},
	copyright = {GPL-2},
	shorttitle = {ggtext},
	url = {https://CRAN.R-project.org/package=ggtext},
	abstract = {A 'ggplot2' extension that enables the rendering of complex formatted plot labels (titles, subtitles, facet labels, axis labels, etc.). Text boxes with automatic word wrap are also supported.},
	urldate = {2022-10-17},
	author = {Wilke, Claus O. and Wiernik
     
    (@bmwiernik), Brenton M.},
	month = sep,
	year = {2022},
}

@misc{wilke_ungewiz_2022,
	title = {Ungewiz: {Tools} for visualizing uncertainty with ggplot2},
	url = {https://github.com/wilkelab/ungeviz},
	author = {Wilke, Claus},
	year = {2022},
}

@misc{pedersen_scico_2022,
	title = {scico: {Colour} {Palettes} {Based} on the {Scientific} {Colour}-{Maps}},
	copyright = {MIT + file LICENSE},
	shorttitle = {scico},
	url = {https://CRAN.R-project.org/package=scico},
	abstract = {Colour choice in information visualisation is important in order to avoid being mislead by inherent bias in the used colour palette. The 'scico' package provides access to the perceptually uniform and colour-blindness friendly palettes developed by Fabio Crameri and released under the "Scientific Colour-Maps" moniker. The package contains 24 different palettes and includes both diverging and sequential types.},
	urldate = {2022-10-17},
	author = {Pedersen, Thomas Lin and Crameri, Fabio},
	month = aug,
	year = {2022},
}

@article{chambers_random_2013,
	title = {A {Random} {Effect} {Block} {Bootstrap} for {Clustered} {Data}},
	volume = {22},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2012.681216},
	doi = {10.1080/10618600.2012.681216},
	number = {2},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Chambers, Raymond and Chandra, Hukum},
	month = apr,
	year = {2013},
	note = {Publisher: Taylor \& Francis},
	keywords = {notion},
	pages = {452--470},
	annote = {doi: 10.1080/10618600.2012.681216},
}

@article{meteyard_best_2020,
	title = {Best practice guidance for linear mixed-effects models in psychological science},
	volume = {112},
	issn = {0749-596X},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X20300061},
	doi = {10.1016/j.jml.2020.104092},
	abstract = {The use of Linear Mixed-effects Models (LMMs) is set to dominate statistical analyses in psychological science and may become the default approach to analyzing quantitative data. The rapid growth in adoption of LMMs has been matched by a proliferation of differences in practice. Unless this diversity is recognized, and checked, the field shall reap enormous difficulties in the future when attempts are made to consolidate or synthesize research findings. Here we examine this diversity using two methods – a survey of researchers (n = 163) and a quasi-systematic review of papers using LMMs (n = 400). The survey reveals substantive concerns among psychologists using or planning to use LMMs and an absence of agreed standards. The review of papers complements the survey, showing variation in how the models are built, how effects are evaluated and, most worryingly, how models are reported. Using these data as our departure point, we present a set of best practice guidance, focusing on the reporting of LMMs. It is the authors’ intention that the paper supports a step-change in the reporting of LMMs across the psychological sciences, preventing a trajectory in which findings reported today cannot be transparently understood and used tomorrow.},
	journal = {Journal of Memory and Language},
	author = {Meteyard, Lotte and Davies, Robert A.I.},
	month = jun,
	year = {2020},
	keywords = {Hierarchical models, Linear mixed effects models, Multilevel models, notion},
	pages = {104092},
}

@article{meteyard_best_2020-1,
	title = {Best practice guidance for linear mixed-effects models in psychological science},
	volume = {112},
	issn = {0749-596X},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X20300061},
	doi = {10.1016/j.jml.2020.104092},
	abstract = {The use of Linear Mixed-effects Models (LMMs) is set to dominate statistical analyses in psychological science and may become the default approach to analyzing quantitative data. The rapid growth in adoption of LMMs has been matched by a proliferation of differences in practice. Unless this diversity is recognized, and checked, the field shall reap enormous difficulties in the future when attempts are made to consolidate or synthesize research findings. Here we examine this diversity using two methods – a survey of researchers (n = 163) and a quasi-systematic review of papers using LMMs (n = 400). The survey reveals substantive concerns among psychologists using or planning to use LMMs and an absence of agreed standards. The review of papers complements the survey, showing variation in how the models are built, how effects are evaluated and, most worryingly, how models are reported. Using these data as our departure point, we present a set of best practice guidance, focusing on the reporting of LMMs. It is the authors’ intention that the paper supports a step-change in the reporting of LMMs across the psychological sciences, preventing a trajectory in which findings reported today cannot be transparently understood and used tomorrow.},
	language = {en},
	urldate = {2022-10-18},
	journal = {Journal of Memory and Language},
	author = {Meteyard, Lotte and Davies, Robert A. I.},
	month = jun,
	year = {2020},
	keywords = {Hierarchical models, Linear mixed effects models, Multilevel models, notion},
	pages = {104092},
	file = {Akzeptierte Version:/Users/luca/Zotero/storage/UKV7HSXJ/Meteyard und Davies - 2020 - Best practice guidance for linear mixed-effects mo.pdf:application/pdf;ScienceDirect Snapshot:/Users/luca/Zotero/storage/WWBLG2BW/S0749596X20300061.html:text/html},
}

@article{schad_how_2020,
	title = {How to capitalize on a priori contrasts in linear (mixed) models: {A} tutorial},
	volume = {110},
	issn = {0749-596X},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X19300695},
	doi = {10.1016/j.jml.2019.104038},
	abstract = {Factorial experiments in research on memory, language, and in other areas are often analyzed using analysis of variance (ANOVA). However, for effects with more than one numerator degrees of freedom, e.g., for experimental factors with more than two levels, the ANOVA omnibus F-test is not informative about the source of a main effect or interaction. Because researchers typically have specific hypotheses about which condition means differ from each other, a priori contrasts (i.e., comparisons planned before the sample means are known) between specific conditions or combinations of conditions are the appropriate way to represent such hypotheses in the statistical model. Many researchers have pointed out that contrasts should be “tested instead of, rather than as a supplement to, the ordinary ‘omnibus’ F test” (Hays, 1973, p. 601). In this tutorial, we explain the mathematics underlying different kinds of contrasts (i.e., treatment, sum, repeated, polynomial, custom, nested, interaction contrasts), discuss their properties, and demonstrate how they are applied in the R System for Statistical Computing (R Core Team, 2018). In this context, we explain the generalized inverse which is needed to compute the coefficients for contrasts that test hypotheses that are not covered by the default set of contrasts. A detailed understanding of contrast coding is crucial for successful and correct specification in linear models (including linear mixed models). Contrasts defined a priori yield far more useful confirmatory tests of experimental hypotheses than standard omnibus F-tests. Reproducible code is available from https://osf.io/7ukf6/.},
	journal = {Journal of Memory and Language},
	author = {Schad, Daniel J. and Vasishth, Shravan and Hohenstein, Sven and Kliegl, Reinhold},
	month = feb,
	year = {2020},
	keywords = {A priori hypotheses, Contrasts, Linear models, Null hypothesis significance testing, notion},
	pages = {104038},
}

@article{mohr_boisberlin_2016,
	title = {{BOiS}—{Berlin} {Object} in {Scene} {Database}: {Controlled} {Photographic} {Images} for {Visual} {Search} {Experiments} with {Quantified} {Contextual} {Priors}},
	volume = {7},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00749},
	journal = {Frontiers in Psychology},
	author = {Mohr, Johannes and Seyfarth, Julia and Lueschow, Andreas and Weber, Joachim E. and Wichmann, Felix A. and Obermayer, Klaus},
	year = {2016},
	keywords = {notion},
}

@article{brehm_contrast_2022,
	title = {Contrast coding choices in a decade of mixed models},
	volume = {125},
	issn = {0749-596X},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X22000213},
	doi = {10.1016/j.jml.2022.104334},
	abstract = {Contrast coding in regression models, including mixed-effect models, changes what the terms in the model mean. In particular, it determines whether or not model terms should be interpreted as main effects. This paper highlights how opaque descriptions of contrast coding have affected the field of psycholinguistics. We begin with a reproducible example in R using simulated data to demonstrate how incorrect conclusions can be made from mixed models; this also serves as a primer on contrast coding for statistical novices. We then present an analysis of 3384 papers from the field of psycholinguistics that we coded based upon whether a clear description of contrast coding was present. This analysis demonstrates that the majority of the psycholinguistic literature does not transparently describe contrast coding choices, posing an important challenge to reproducibility and replicability in our field.},
	journal = {Journal of Memory and Language},
	author = {Brehm, Laurel and Alday, Phillip M.},
	month = aug,
	year = {2022},
	keywords = {Contrasts, notion, Meta-science, Mixed effect models, Replication crisis},
	pages = {104334},
}

@article{brehm_contrast_2022-1,
	title = {Contrast coding choices in a decade of mixed models},
	volume = {125},
	issn = {0749-596X},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X22000213},
	doi = {10.1016/j.jml.2022.104334},
	abstract = {Contrast coding in regression models, including mixed-effect models, changes what the terms in the model mean. In particular, it determines whether or not model terms should be interpreted as main effects. This paper highlights how opaque descriptions of contrast coding have affected the field of psycholinguistics. We begin with a reproducible example in R using simulated data to demonstrate how incorrect conclusions can be made from mixed models; this also serves as a primer on contrast coding for statistical novices. We then present an analysis of 3384 papers from the field of psycholinguistics that we coded based upon whether a clear description of contrast coding was present. This analysis demonstrates that the majority of the psycholinguistic literature does not transparently describe contrast coding choices, posing an important challenge to reproducibility and replicability in our field.},
	language = {en},
	urldate = {2022-10-20},
	journal = {Journal of Memory and Language},
	author = {Brehm, Laurel and Alday, Phillip M.},
	month = aug,
	year = {2022},
	keywords = {Contrasts, notion, Meta-science, Mixed effect models, Replication crisis},
	pages = {104334},
	file = {ScienceDirect Snapshot:/Users/luca/Zotero/storage/IZXSAIVI/S0749596X22000213.html:text/html},
}

@article{harrison_brief_2018,
	title = {A brief introduction to mixed effects modelling and multi-model inference in ecology},
	volume = {6},
	doi = {10.7717/peerj.4794},
	journal = {PeerJ},
	author = {Harrison, Xavier and Donaldson, Lynda and Correa, Maru and Evans, Julian and Fisher, David and Goodwin, Cecily and Robinson, Beth and Hodgson, David and Inger, Richard},
	month = may,
	year = {2018},
	pages = {e4794},
}

@article{meteyard_best_2020-2,
	title = {Best practice guidance for linear mixed-effects models in psychological science},
	volume = {112},
	issn = {0749-596X},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X20300061},
	doi = {10.1016/j.jml.2020.104092},
	abstract = {The use of Linear Mixed-effects Models (LMMs) is set to dominate statistical analyses in psychological science and may become the default approach to analyzing quantitative data. The rapid growth in adoption of LMMs has been matched by a proliferation of differences in practice. Unless this diversity is recognized, and checked, the field shall reap enormous difficulties in the future when attempts are made to consolidate or synthesize research findings. Here we examine this diversity using two methods – a survey of researchers (n = 163) and a quasi-systematic review of papers using LMMs (n = 400). The survey reveals substantive concerns among psychologists using or planning to use LMMs and an absence of agreed standards. The review of papers complements the survey, showing variation in how the models are built, how effects are evaluated and, most worryingly, how models are reported. Using these data as our departure point, we present a set of best practice guidance, focusing on the reporting of LMMs. It is the authors’ intention that the paper supports a step-change in the reporting of LMMs across the psychological sciences, preventing a trajectory in which findings reported today cannot be transparently understood and used tomorrow.},
	language = {en},
	urldate = {2022-10-21},
	journal = {Journal of Memory and Language},
	author = {Meteyard, Lotte and Davies, Robert A. I.},
	month = jun,
	year = {2020},
	keywords = {Hierarchical models, Linear mixed effects models, Multilevel models},
	pages = {104092},
	file = {Akzeptierte Version:/Users/luca/Zotero/storage/SP6E8VQY/Meteyard und Davies - 2020 - Best practice guidance for linear mixed-effects mo.pdf:application/pdf;ScienceDirect Snapshot:/Users/luca/Zotero/storage/4C9QFJCN/S0749596X20300061.html:text/html},
}

@incollection{singmann_introduction_2019-1,
	title = {An introduction to mixed models for experimental psychology},
	booktitle = {New methods in cognitive psychology},
	publisher = {Routledge},
	author = {Singmann, H and Kellen, David},
	year = {2019},
	pages = {4--31},
}

@article{bono_report_2021,
	title = {Report {Quality} of {Generalized} {Linear} {Mixed} {Models} in {Psychology}: {A} {Systematic} {Review}},
	volume = {12},
	issn = {1664-1078},
	shorttitle = {Report {Quality} of {Generalized} {Linear} {Mixed} {Models} in {Psychology}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2021.666182},
	abstract = {Generalized linear mixed models (GLMMs) estimate fixed and random effects and are especially useful when the dependent variable is binary, ordinal, count or quantitative but not normally distributed. They are also useful when the dependent variable involves repeated measures, since GLMMs can model autocorrelation. This study aimed to determine how and how often GLMMs are used in psychology and to summarize how the information about them is presented in published articles. Our focus in this respect was mainly on frequentist models. In order to review studies applying GLMMs in psychology we searched the Web of Science for articles published over the period 2014–2018. A total of 316 empirical articles were selected for trend study from 2014 to 2018. We then conducted a systematic review of 118 GLMM analyses from 80 empirical articles indexed in Journal Citation Reports during 2018 in order to evaluate report quality. Results showed that the use of GLMMs increased over time and that 86.4\% of articles were published in first- or second-quartile journals. Although GLMMs have, in recent years, been increasingly used in psychology, most of the important information about them was not stated in the majority of articles. Report quality needs to be improved in line with current recommendations for the use of GLMMs.},
	urldate = {2022-10-21},
	journal = {Frontiers in Psychology},
	author = {Bono, Roser and Alarcón, Rafael and Blanca, María J.},
	year = {2021},
	file = {Full Text PDF:/Users/luca/Zotero/storage/S2PDVGJM/Bono et al. - 2021 - Report Quality of Generalized Linear Mixed Models .pdf:application/pdf},
}

@article{blanca_current_2018,
	title = {Current {Practices} in {Data} {Analysis} {Procedures} in {Psychology}: {What} {Has} {Changed}?},
	volume = {9},
	issn = {1664-1078},
	shorttitle = {Current {Practices} in {Data} {Analysis} {Procedures} in {Psychology}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02558},
	abstract = {This paper analyzes current practices in psychology in the use of research methods and data analysis procedures (DAP) and aims to determine whether researchers are now using more sophisticated and advanced DAP than were employed previously. We reviewed empirical research published recently in prominent journals from the USA and Europe corresponding to the main psychological categories of Journal Citation Reports and examined research methods, number of studies, number and type of DAP, and statistical package. The 288 papers reviewed used 663 different DAP. Experimental and correlational studies were the most prevalent, depending on the specific field of psychology. Two-thirds of the papers reported a single study, although those in journals with an experimental focus typically described more. The papers mainly used parametric tests for comparison and statistical techniques for analyzing relationships among variables. Regarding the former, the most frequently used procedure was ANOVA, with mixed factorial ANOVA being the most prevalent. A decline in the use of non-parametric analysis was observed in relation to previous research. Relationships among variables were most commonly examined using regression models, with hierarchical regression and mediation analysis being the most prevalent procedures. There was also a decline in the use of stepwise regression and an increase in the use of structural equation modeling, confirmatory factor analysis, and hierarchical linear modeling. Overall, the results show that recent empirical studies published in journals belonging to the main areas of psychology are employing more varied and advanced statistical techniques of greater computational complexity.},
	urldate = {2022-10-21},
	journal = {Frontiers in Psychology},
	author = {Blanca, María J. and Alarcón, Rafael and Bono, Roser},
	year = {2018},
	file = {Full Text PDF:/Users/luca/Zotero/storage/AER4XKDS/Blanca et al. - 2018 - Current Practices in Data Analysis Procedures in P.pdf:application/pdf},
}

@incollection{van_zandt_analysis_2002,
	title = {Analysis of response time distributions},
	volume = {4},
	booktitle = {Stevens’ handbook of experimental psychology},
	author = {Van Zandt, T},
	year = {2002},
	pages = {461--516},
}

@article{micceri_unicorn_1989,
	title = {The unicorn, the normal curve, and other improbable creatures},
	volume = {105},
	issn = {1939-1455},
	doi = {10.1037/0033-2909.105.1.156},
	abstract = {An investigation of the distributional characteristics of 440 large-sample achievement and psychometric measures found all to be significantly nonnormal at the alpha .01 significance level. Several classes of contamination were found, including tail weights from the uniform to the double exponential, exponential-level asymmetry, severe digit preferences, multimodalities, and modes external to the mean/median interval. Thus, the underlying tenets of normality-assuming statistics appear fallacious for these commonly used types of data. However, findings here also fail to support the types of distributions used in most prior robustness research suggesting the failure of such statistics under nonnormal conditions. A reevaluation of the statistical robustness literature appears appropriate in light of these findings. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Psychological Bulletin},
	author = {Micceri, Theodore},
	year = {1989},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Psychometrics, Achievement Measures, Normal Distribution, Statistical Measurement},
	pages = {156--166},
	file = {Snapshot:/Users/luca/Zotero/storage/ZZIQ9I7F/1989-14214-001.html:text/html},
}

@article{blanca_skewness_2013,
	title = {Skewness and kurtosis in real data samples},
	volume = {9},
	issn = {1614-2241},
	doi = {10.1027/1614-2241/a000057},
	abstract = {Parametric statistics are based on the assumption of normality. Recent findings suggest that Type I error and power can be adversely affected when data are non-normal. This paper aims to assess the distributional shape of real data by examining the values of the third and fourth central moments as a measurement of skewness and kurtosis in small samples. The analysis concerned 693 distributions with a sample size ranging from 10 to 30. Measures of cognitive ability and of other psychological variables were included. The results showed that skewness ranged between −2.49 and 2.33. The values of kurtosis ranged between −1.92 and 7.41. Considering skewness and kurtosis together the results indicated that only 5.5\% of distributions were close to expected values under normality. Although extreme contamination does not seem to be very frequent, the findings are consistent with previous research suggesting that normality is not the rule with real data. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	journal = {Methodology: European Journal of Research Methods for the Behavioral and Social Sciences},
	author = {Blanca, María J. and Arnau, Jaume and López-Montiel, Dolores and Bono, Roser and Bendayan, Rebecca},
	year = {2013},
	note = {Place: Germany
Publisher: Hogrefe Publishing},
	keywords = {Normal Distribution, Skewed Distribution, Statistical Data, Statistical Samples, Statistics},
	pages = {78--84},
	file = {Akzeptierte Version:/Users/luca/Zotero/storage/632Q97TB/Blanca et al. - 2013 - Skewness and kurtosis in real data samples.pdf:application/pdf;Snapshot:/Users/luca/Zotero/storage/4NSVV2FI/2013-13782-004.html:text/html},
}

@article{brockmole_contextual_2006,
	title = {Contextual cueing in naturalistic scenes: {Global} and local contexts},
	volume = {32},
	issn = {1939-1285},
	shorttitle = {Contextual cueing in naturalistic scenes},
	doi = {10.1037/0278-7393.32.4.699},
	abstract = {In contextual cueing, the position of a target within a group of distractors is learned over repeated exposure to a display with reference to a few nearby items rather than to the global pattern created by the elements. The authors contrasted the role of global and local contexts for contextual cueing in naturalistic scenes. Experiment 1 showed that learned target positions transfer when local information is altered but not when global information is changed. Experiment 2 showed that scene-target covariation is learned more slowly when local, but not global, information is repeated across trials than when global but not local information is repeated. Thus, in naturalistic scenes, observers are biased to associate target locations with global contexts. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	author = {Brockmole, James R. and Castelhano, Monica S. and Henderson, John M.},
	year = {2006},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Attention, notion, Contextual Associations, Contextual Cues, Cues, Visual Memory},
	pages = {699--706},
	file = {Snapshot:/Users/luca/Zotero/storage/M6XDPVC8/2006-08497-004.html:text/html},
}

@article{jiang_what_2004,
	title = {What is learned in spatial contextual cuing— configuration or individual locations?},
	volume = {66},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03194893},
	doi = {10.3758/BF03194893},
	abstract = {With the use of spatial contextual cuing, we tested whether subjects learned to associate target locations with overall configurations of distractors or with individual locations of distractors. In Experiment 1, subjects were trained on 36 visual search displays that contained 36 sets of distractor locations and 18 target locations. Each target location was paired with two sets of distractor locations on separate trials. After training, the subjects showed perfect transfer to recombined displays, which were created by combining half of one trained distractor set with half of another trained distractor set. This result suggests that individual distractor locations were sufficient to cue the target location. In Experiment 2, the subjects showed good transfer from trained displays to rescaled, displaced, and perceptually regrouped displays, suggesting that the relative locations among items were also learned. Thus, both individual target-distractor associations and configural associations are learned in contextual cuing.},
	language = {en},
	number = {3},
	urldate = {2022-10-23},
	journal = {Perception \& Psychophysics},
	author = {Jiang, Yuhong and Wagner, Laura C.},
	month = apr,
	year = {2004},
	keywords = {notion, Distractor Location, Global Configuration, Implicit Learning, Target Location, Transfer Session},
	pages = {454--463},
	file = {Full Text PDF:/Users/luca/Zotero/storage/SPBNIRTE/Jiang und Wagner - 2004 - What is learned in spatial contextual cuing— confi.pdf:application/pdf},
}

@article{lo_transform_2015,
	title = {To transform or not to transform: using generalized linear mixed models to analyse reaction time data},
	volume = {6},
	issn = {1664-1078},
	shorttitle = {To transform or not to transform},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171},
	abstract = {Linear mixed-effect models (LMMs) are being increasingly widely used in psychology to analyse multi-level research designs. This feature allows LMMs to address some of the problems identified by Speelman and McGann (2013) about the use of mean data, because they do not average across individual responses. However, recent guidelines for using LMM to analyse skewed reaction time (RT) data collected in many cognitive psychological studies recommend the application of non-linear transformations to satisfy assumptions of normality. Uncritical adoption of this recommendation has important theoretical implications which can yield misleading conclusions. For example, Balota et al. (2013) showed that analyses of raw RT produced additive effects of word frequency and stimulus quality on word identification, which conflicted with the interactive effects observed in analyses of transformed RT. Generalized linear mixed-effect models (GLMM) provide a solution to this problem by satisfying normality assumptions without the need for transformation. This allows differences between individuals to be properly assessed, using the metric most appropriate to the researcher's theoretical context. We outline the major theoretical decisions involved in specifying a GLMM, and illustrate them by reanalysing Balota et al.'s datasets. We then consider the broader benefits of using GLMM to investigate individual differences.},
	urldate = {2022-10-23},
	journal = {Frontiers in Psychology},
	author = {Lo, Steson and Andrews, Sally},
	year = {2015},
	keywords = {notion},
	file = {Full Text PDF:/Users/luca/Zotero/storage/6HYKQWE6/Lo und Andrews - 2015 - To transform or not to transform using generalize.pdf:application/pdf},
}

@article{box_analysis_1964,
	title = {An analysis of transformations},
	volume = {26},
	journal = {Journal of the Royal Statistical Society B},
	author = {Box, G. E. P. and Cox, D. R.},
	year = {1964},
	pages = {211--252},
}

@article{yeo_new_2000,
	title = {A new family of power transformations to improve normality or symmetry},
	volume = {87},
	doi = {10.1093/biomet/87.4.954},
	journal = {Biometrika},
	author = {Yeo, In-Kwon and Johnson, Richard},
	month = dec,
	year = {2000},
}

@misc{aust_papaja_2022,
	title = {papaja: {Prepare} {American} {Psychological} {Association} {Journal} {Articles} with {R} {Markdown}},
	copyright = {MIT + file LICENSE},
	shorttitle = {papaja},
	url = {https://CRAN.R-project.org/package=papaja},
	abstract = {Tools to create dynamic, submission-ready manuscripts, which conform to American Psychological Association manuscript guidelines. We provide R Markdown document formats for manuscripts (PDF and Word) and revision letters (PDF). Helper functions facilitate reporting statistical analyses or create publication-ready tables and plots.},
	urldate = {2022-10-25},
	author = {Aust, Frederik and Barth, Marius and Diedenhofen, Birk and Stahl, Christoph and Casillas, Joseph V. and Siegel, Rudolf},
	month = jul,
	year = {2022},
}

@misc{noauthor_cran_nodate,
	title = {{CRAN} - {Package} knitr},
	url = {https://cran.r-project.org/web/packages/knitr/index.html},
	urldate = {2022-10-25},
	file = {CRAN - Package knitr:/Users/luca/Zotero/storage/Y9QSTUHU/index.html:text/html},
}

@misc{xie__aut_knitr_2022,
	title = {knitr: {A} {General}-{Purpose} {Package} for {Dynamic} {Report} {Generation} in {R}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL]},
	shorttitle = {knitr},
	url = {https://CRAN.R-project.org/package=knitr},
	abstract = {Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.},
	urldate = {2022-10-25},
	author = {Xie  [aut, Yihui and cre and Sarma, Abhraneel and Vogt, Adam and Andrew, Alastair and Zvoleff, Alex and Al-Zubaidi, Amar and http://www.andre-simon.de), Andre Simon (the CSS files under inst/themes/ were derived from the Highlight package and Atkins, Aron and Wolen, Aaron and Manton, Ashley and Yasumoto, Atsushi and Baumer, Ben and Diggs, Brian and Zhang, Brian and Yapparov, Bulat and Pereira, Cassio and Dervieux, Christophe and Hall, David and Hugh-Jones, David and Robinson, David and Hemken, Doug and Murdoch, Duncan and Campitelli, Elio and Hughes, Ellis and Riederer, Emily and Hirschmann, Fabian and Simeon, Fitch and Fang, Forest and inst/misc/Sweavel.sty), Frank E. Harrell Jr (the Sweavel package at and Aden-Buie, Garrick and Detrez, Gregoire and Wickham, Hadley and Zhu, Hao and Jeon, Heewon and Bengtsson, Henrik and Yutani, Hiroaki and Lyttle, Ian and Daniel, Hodges and Bien, Jacob and Burkhead, Jake and Manton, James and Lander, Jared and Punyon, Jason and Luraschi, Javier and Arnold, Jeff and Bryan, Jenny and inst/misc/docco-classic.css), Jeremy Ashkenas (the CSS file at and Stephens, Jeremy and Hester, Jim and Cheng, Joe and Ranke, Johannes and Honaker, John and Muschelli, John and Keane, Jonathan and Allaire, J. J. and Toloe, Johan and Sidi, Jonathan and Larmarange, Joseph and Barnier, Julien and Zhong, Kaiyin and Slowikowski, Kamil and Forner, Karl and Smith, Kevin K. and Mueller, Kirill and Takahashi, Kohske and Walthert, Lorenz and Gallindo, Lucas and Hofert, Marius and Modrák, Martin and Chirico, Michael and Friendly, Michael and Bojanowski, Michal and Kuhlmann, Michel and Patrick, Miller and Caballero, Nacho and Salkowski, Nick and Hansen, Niels Richard and Ross, Noam and Mahdi, Obada and Krivitsky, Pavel N. and Li, Qiang and Vaidyanathan, Ramnath and Cotton, Richard and Krzyzanowski, Robert and Copetti, Rodrigo and Francois, Romain and Williamson, Ruaridh and Mati, Sagiru and Kostyshak, Scott and Meyer, Sebastian and Brouwer, Sietse and Bernard, Simon de and Rousseau, Sylvain and Wei, Taiyun and Assus, Thibaut and Lamadon, Thibaut and Leeper, Thomas and Mastny, Tim and Torsney-Weir, Tom and Davis, Trevor and Veitas, Viktoras and Zhu, Weicheng and Wu, Wush and Foster, Zachary and Kamvar, Zhian N.},
	month = aug,
	year = {2022},
	keywords = {ReproducibleResearch},
}

@misc{xie__aut_knitr_2022-1,
	title = {knitr: {A} {General}-{Purpose} {Package} for {Dynamic} {Report} {Generation} in {R}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL]},
	shorttitle = {knitr},
	url = {https://CRAN.R-project.org/package=knitr},
	abstract = {Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.},
	urldate = {2022-10-25},
	author = {Xie  [aut, Yihui and cre and Sarma, Abhraneel and Vogt, Adam and Andrew, Alastair and Zvoleff, Alex and Al-Zubaidi, Amar and http://www.andre-simon.de), Andre Simon (the CSS files under inst/themes/ were derived from the Highlight package and Atkins, Aron and Wolen, Aaron and Manton, Ashley and Yasumoto, Atsushi and Baumer, Ben and Diggs, Brian and Zhang, Brian and Yapparov, Bulat and Pereira, Cassio and Dervieux, Christophe and Hall, David and Hugh-Jones, David and Robinson, David and Hemken, Doug and Murdoch, Duncan and Campitelli, Elio and Hughes, Ellis and Riederer, Emily and Hirschmann, Fabian and Simeon, Fitch and Fang, Forest and inst/misc/Sweavel.sty), Frank E. Harrell Jr (the Sweavel package at and Aden-Buie, Garrick and Detrez, Gregoire and Wickham, Hadley and Zhu, Hao and Jeon, Heewon and Bengtsson, Henrik and Yutani, Hiroaki and Lyttle, Ian and Daniel, Hodges and Bien, Jacob and Burkhead, Jake and Manton, James and Lander, Jared and Punyon, Jason and Luraschi, Javier and Arnold, Jeff and Bryan, Jenny and inst/misc/docco-classic.css), Jeremy Ashkenas (the CSS file at and Stephens, Jeremy and Hester, Jim and Cheng, Joe and Ranke, Johannes and Honaker, John and Muschelli, John and Keane, Jonathan and Allaire, J. J. and Toloe, Johan and Sidi, Jonathan and Larmarange, Joseph and Barnier, Julien and Zhong, Kaiyin and Slowikowski, Kamil and Forner, Karl and Smith, Kevin K. and Mueller, Kirill and Takahashi, Kohske and Walthert, Lorenz and Gallindo, Lucas and Hofert, Marius and Modrák, Martin and Chirico, Michael and Friendly, Michael and Bojanowski, Michal and Kuhlmann, Michel and Patrick, Miller and Caballero, Nacho and Salkowski, Nick and Hansen, Niels Richard and Ross, Noam and Mahdi, Obada and Krivitsky, Pavel N. and Li, Qiang and Vaidyanathan, Ramnath and Cotton, Richard and Krzyzanowski, Robert and Copetti, Rodrigo and Francois, Romain and Williamson, Ruaridh and Mati, Sagiru and Kostyshak, Scott and Meyer, Sebastian and Brouwer, Sietse and Bernard, Simon de and Rousseau, Sylvain and Wei, Taiyun and Assus, Thibaut and Lamadon, Thibaut and Leeper, Thomas and Mastny, Tim and Torsney-Weir, Tom and Davis, Trevor and Veitas, Viktoras and Zhu, Weicheng and Wu, Wush and Foster, Zachary and Kamvar, Zhian N.},
	month = aug,
	year = {2022},
	keywords = {ReproducibleResearch},
}

@misc{xie__aut_knitr_2022-2,
	title = {knitr: {A} {General}-{Purpose} {Package} for {Dynamic} {Report} {Generation} in {R}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL]},
	shorttitle = {knitr},
	url = {https://CRAN.R-project.org/package=knitr},
	abstract = {Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.},
	urldate = {2022-10-25},
	author = {Xie  [aut, Yihui and cre and Sarma, Abhraneel and Vogt, Adam and Andrew, Alastair and Zvoleff, Alex and Al-Zubaidi, Amar and http://www.andre-simon.de), Andre Simon (the CSS files under inst/themes/ were derived from the Highlight package and Atkins, Aron and Wolen, Aaron and Manton, Ashley and Yasumoto, Atsushi and Baumer, Ben and Diggs, Brian and Zhang, Brian and Yapparov, Bulat and Pereira, Cassio and Dervieux, Christophe and Hall, David and Hugh-Jones, David and Robinson, David and Hemken, Doug and Murdoch, Duncan and Campitelli, Elio and Hughes, Ellis and Riederer, Emily and Hirschmann, Fabian and Simeon, Fitch and Fang, Forest and inst/misc/Sweavel.sty), Frank E. Harrell Jr (the Sweavel package at and Aden-Buie, Garrick and Detrez, Gregoire and Wickham, Hadley and Zhu, Hao and Jeon, Heewon and Bengtsson, Henrik and Yutani, Hiroaki and Lyttle, Ian and Daniel, Hodges and Bien, Jacob and Burkhead, Jake and Manton, James and Lander, Jared and Punyon, Jason and Luraschi, Javier and Arnold, Jeff and Bryan, Jenny and inst/misc/docco-classic.css), Jeremy Ashkenas (the CSS file at and Stephens, Jeremy and Hester, Jim and Cheng, Joe and Ranke, Johannes and Honaker, John and Muschelli, John and Keane, Jonathan and Allaire, J. J. and Toloe, Johan and Sidi, Jonathan and Larmarange, Joseph and Barnier, Julien and Zhong, Kaiyin and Slowikowski, Kamil and Forner, Karl and Smith, Kevin K. and Mueller, Kirill and Takahashi, Kohske and Walthert, Lorenz and Gallindo, Lucas and Hofert, Marius and Modrák, Martin and Chirico, Michael and Friendly, Michael and Bojanowski, Michal and Kuhlmann, Michel and Patrick, Miller and Caballero, Nacho and Salkowski, Nick and Hansen, Niels Richard and Ross, Noam and Mahdi, Obada and Krivitsky, Pavel N. and Li, Qiang and Vaidyanathan, Ramnath and Cotton, Richard and Krzyzanowski, Robert and Copetti, Rodrigo and Francois, Romain and Williamson, Ruaridh and Mati, Sagiru and Kostyshak, Scott and Meyer, Sebastian and Brouwer, Sietse and Bernard, Simon de and Rousseau, Sylvain and Wei, Taiyun and Assus, Thibaut and Lamadon, Thibaut and Leeper, Thomas and Mastny, Tim and Torsney-Weir, Tom and Davis, Trevor and Veitas, Viktoras and Zhu, Weicheng and Wu, Wush and Foster, Zachary and Kamvar, Zhian N.},
	month = aug,
	year = {2022},
	keywords = {ReproducibleResearch},
}

@misc{zhu__aut_kableextra_2021,
	title = {{kableExtra}: {Construct} {Complex} {Table} with 'kable' and {Pipe} {Syntax}},
	copyright = {MIT + file LICENSE},
	shorttitle = {{kableExtra}},
	url = {https://CRAN.R-project.org/package=kableExtra},
	abstract = {Build complex HTML or 'LaTeX' tables using 'kable()' from 'knitr' and the piping syntax from 'magrittr'. Function 'kable()' is a light weight table generator coming from 'knitr'. This package simplifies the way to manipulate the HTML or 'LaTeX' codes generated by 'kable()' and allows users to construct complex tables and customize styles using a readable syntax.},
	urldate = {2022-10-25},
	author = {Zhu  [aut, Hao and cre and Travison, Thomas and Tsai, Timothy and Beasley, Will and Xie, Yihui and Yu, GuangChuang and Laurent, Stéphane and Shepherd, Rob and Sidi, Yoni and Salzer, Brian and Gui, George and Fan, Yeliang and Murdoch, Duncan and Evans, Bill},
	month = feb,
	year = {2021},
}
